---
title: Adam
description: The best version of all adaptive learning rate optimization algorithms.
date: 2024-05-05
tag: Optimization
published: true
type: Post
---

## Mathematics of Adam

## Implementation of Adam

## Conclusion

## Code

## References

1. Sebastian Ruder. "An overview of gradient descent optimization algorithms." [arXiv:1609.04747](https://arxiv.org/abs/1609.04747) (2016).
2. Diederik P. Kingma, Jimmy Ba. "Adam: A Method for Stochastic Optimization." [arXiv:1412.6980](https://arxiv.org/abs/1412.6980) (2014).
