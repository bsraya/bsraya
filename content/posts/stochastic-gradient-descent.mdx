---
title: Stochastic Gradient Descent
description: Minimizing cost functions with less data points
date: 2022-04-04
tag: Optimization
type: Post
---

<SeriesTable
  title="Gradient Descent Algorithm"
  series={[
    {
      title: "Introduction to Gradient Descent Algorithm",
      current: false,
    },
    {
      title: "Mathematics of Gradient Descent",
      current: false,
    },
    {
      title: "Batch Gradient Descent",
      current: false,
    },
    {
      title: "Mini Batch Gradient Descent",
      current: false,
    },
    {
      title: "Stochastic Gradient Descent",
      current: true,
    },
    {
      title: "SGD with Momentum",
      current: false,
    },
    {
      title: "SGD with Nesterov",
      current: false,
    },
    {
      title: "Adagrad",
      current: false,
    },
    {
      title: "Adadelta",
      current: false,
    },
  ]}
/>

Previously, we have learned that BGD updates parameters $\beta_0$ and $\beta_1$, the intercept and the coefficient values respectively, only after it has seen the entire dataset.
As for MBGD, it only updates them after it has seen a fraction of the entire dataset.

In this post, we are going to implement another variation of Gradient Descent called Stochastic Gradient Descent, or SGD we can call it.
## Introduction

SGD is an optimization algorithm that is derived from BGD and MBGD.
An optimization algorithm helps us to find the best fit line for our data.
In other words, we want to find the best value for parameters $\beta_0$ and $\beta_1$ so that the line sits right in a position where it's close to most data points.
As the regression line moves toward where most data points sit, the cost function, in this case the Mean Square Error value, will decrease.

The only difference between SGD and the other previous algorithms we have covered is that 
it updates parameters $\beta_0$ and $\beta_1$ after it has seen a random data point, as the name suggests.

Before we start, we should get ourselves familiar with the mathematical part of this algorithm.

## Mathematics of SGD

The whole idea of SGD is that it updates the parameters each time we see a random data points.

So, we are going to do a litle review to refresh our memory from the first post in this series.

Remember that the cost function that we are going to minimized in BGD is

$$
  J(\beta_i) = \frac{1}{N} \sum_{i=1}^N (f(x) - y_1)^2
$$

To be clear, we are to express $J(\beta_i)$ as $J(\beta_0, \beta_1)$ where $\beta_0$ is the intercept and $\beta_1$ is the coefficient so that
we know what parameters are being used.

However, since SGD updates parameters $\beta_0$ and $\beta_1$ after seeing a random data points, we do not have to divide the summation by $N$.

Thus, the cost function will be

$$
  J(\beta_0, \beta_1) = \sum_{i=1}^N (f(x) - y_i)^2
$$

The update rules stay the same

$$
  \beta_{i} = \beta_i - \alpha \cdot \frac{\partial}{\partial \beta_i} J(\beta_0, \beta_1)
$$

where $\beta_i$ is the $i$-th coefficient we want to update and $\alpha$ is the learning rate.

Applying Power Rule to the cost function, we have

$$
    \frac{\partial}{\partial \beta_i} J(\beta_0, \beta_1) = 2(f(x) - y_i) \frac{\partial}{\partial \beta_i} (f(x) - y_i)
$$

Let's partially derive the cost function with respect to parameters $\beta_0$ and $\beta_1$.

$$
    \begin{aligned}
        \frac{\partial}{\partial \beta_0} J(\beta_0, \beta_1)
        &= 2 (f(x) - y_i) \frac{\partial}{\partial \beta_0} (\beta_0 + \beta_1 x - y_i) \\
        &= 2 (f(x) - y_i)
    \end{aligned}
$$

$$
    \frac{\partial}{\partial \beta_1} J(\beta_0, \beta_1) = 2(f(x) - y_i)x
$$

Remember that the scalar 2 in the partial derivative equations above can be cancelled out by dividing the SGD cost function by 2.
We called the new customized cost function **One Half Mean Squared Error**.

$$
  J(\beta_0, \beta_1) = \frac{1}{2}(f(x) - y_i)^2
$$

Thus the partial derivatives with respect to $\beta_0$ and $\beta_1$ will be

$$
    \begin{aligned}
        \frac{\partial}{\partial \beta_0} J(\beta_0, \beta_1) = (f(x) - y_i) \\
        \frac{\partial}{\partial \beta_1} J(\beta_0, \beta_1) = (f(x) - y_i) x
    \end{aligned}
$$

Plugging each of the equation above into the update rules with respect to those coefficients, we get

$$
    \begin{aligned}
        \beta_0 = \beta_0 - \alpha \cdot (f(x) - y_i) \\
        \beta_1 = \beta_1 - \alpha \cdot (f(x) - y_i)x
    \end{aligned}
$$

The equations above is a variation of Gradient Descent algorithm that helps us to approximate the minimum value of the cost function by updating $\beta_0$ and $\beta_1$ iteratively.

## Coding

We are going to need two functions to implement SGD.

1. `predict(...)` which received a single data point and returns the predicted value of the data point.
2. `sgd(...)` which received a list of data points and returns the updated coefficients presented in a dataframe.

```python
def predict(intercept, coefficient, x):
    return intercept + coefficient * x

def sgd(x, y, df, epochs, alpha = 0.01):
    intercept = 2.0
    coefficient = -7.5
    sum_error = 0

    rand = np.random.randint(0, len(x))
    prediction = predict(intercept, coefficient, x[rand])
    sum_error = sum_error + (((prediction - y[rand]) ** 2) / 2)
    df.loc[0] = [intercept, coefficient, sum_error]

    for i in range(1,epochs):
        # get random index
        rand = np.random.randint(0, len(x))
        # get random x and y
        x_i, y_i = x[rand], y[rand]
        # get prediction
        prediction = predict(intercept, coefficient, x_i)
        b0_error = prediction - y_i
        b1_error = (prediction - y_i) * x_i

        intercept = intercept - alpha * b0_error
        coefficient = coefficient - alpha * b1_error

        sum_error = (((prediction - y_i) ** 2) / 2)
        df.loc[i] = [intercept, coefficient, sum_error]
    return df
```

Let's compare how SGD and Vanilla Gradient Descent behave.

![SGD vs BGD Pathways](/assets/posts/stochastic-gradient-descent/gd-sgd-pathways.png)

You would notice that the pathway of Vanilla Gradient is much more smoother, 
and the pathway of SGD is much more thicker than Vanilla Gradient Descent pathway.
If we zoom in, we would notice that the SGD pathway is much more noisier.

![Zoomed in SGD vs BGD Pathways](/assets/posts/stochastic-gradient-descent/gd-sgd-pathways-zoomed.png)

There are pros and cons for Vanilla Gradient Descent and SGD.
For Vanilla Gradient Descent, it is slow but it is guaranteed to converge to the global minimum.
In addition to that, it requires more memory and is not suitable for large dataset since datasets have to be loaded to the RAM before training.

On the otherhand, SGD is faster and is suitable for large dataset since it only requires a single data point to be loaded to the RAM.
However, it's not guaranteed to converge to the global minima since it updates parameters $\beta_0$ and $\beta_1$ after seeing a random data point.
Not only that, it would struggle to escape local minima and avoid steep regions in the 3D plot of the cost function.

## References

1. O. Artem. _Stochastic, Batch, and Mini-Batch Gradient Descent_. [https://towardsdatascience.com/stochastic-batch-and-mini-batch-gradient-descent-demystified-8b28978f7f5](https://towardsdatascience.com/stochastic-batch-and-mini-batch-gradient-descent-demystified-8b28978f7f5)
2. P. Sushant. _Batch, Mini Batch, and Stochastic Gradient Descent_. [https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a](https://towardsdatascience.com/batch-mini-batch-stochastic-gradient-descent-7a62ecba642a)
3. Geeksforgeeks. _Difference between Batch Gradient Descent and Stochastic Gradient Descent_. [https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/](https://www.geeksforgeeks.org/difference-between-batch-gradient-descent-and-stochastic-gradient-descent/)
4. Sweta. _Batch, Mini Batch, and Stochastic Gradient Descent_. [https://sweta-nit.medium.com/batch-mini-batch-and-stochastic-gradient-descent-e9bc4cacd461](https://sweta-nit.medium.com/batch-mini-batch-and-stochastic-gradient-descent-e9bc4cacd461)
5. R. Sebastian. _Gradient Descent and Stochastic Gradient Descent_. [https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/](https://rasbt.github.io/mlxtend/user_guide/general_concepts/gradient-optimization/)
6. Geeksforgeeks. _ML | Mini-Batch Gradient Descent with Python_. [https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/](https://www.geeksforgeeks.org/ml-mini-batch-gradient-descent-with-python/)
